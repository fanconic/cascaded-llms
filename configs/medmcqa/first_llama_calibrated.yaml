experiment: first #"first" runs the deferal experiment, "second" runs the online deferral/abstention experiment
seed: 42
results_dir: followup_results
max_new_tokens: 512
calibrate: true
calibration_size: 100
costs:
  output_input_price_ratio: 5
  base_gen_cost: 1.0
  large_inf_cost: 0.3
  large_gen_cost: 5.0
  expert_cost: 6.69 # Adjusted to fir system risk
  mistake_cost: 16.81 # Adjusted to fir system risk
base_model: meta-llama/Llama-3.2-1B-Instruct
large_model: meta-llama/Llama-3.1-8B-Instruct
batch_size: 7 #60
max_input_length: 512
online:
  enable: false
  initial_uncertainty_threshold_base: 5.0
  initial_uncertainty_threshold_large: 5.0
  initial_M: 0.0
  lr_tau: 0.01
  lr_M: 0.005
  error_penalty: 10
sft:
  enable: false
  learning_rate: 0.0001
  buffer_size: 1
  lora_r: 32
  lora_alpha: 64
  lora_dropout: 0.1
verification_fn: surrogate_token_probs
uncertainty_fn: surrogate_token_probs
uncertainty_samples: 1
precomputed:
  enable: true
  generation: true
  verification: true
  uncertainty: true
  path: /home/azureuser/caf83/helm/results/run_20250428_072842_debug_llama_arc_easy/results_debug_llama_arc_easy.csv
dataset:
  name: allenai/ai2_arc
  subset: ARC-Easy
  split: test
  num_samples: -1
device: cuda:0
name_postfix: first_llama_arc_easy_calibrated
