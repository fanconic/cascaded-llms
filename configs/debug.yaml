experiment: second #"first" runs the deferal experiment, "second" runs the online deferral/abstention experiment
seed: 42
results_dir: followup_results_online
max_new_tokens: 512
calibrate: true
calibration_size: 100
costs:
  output_input_price_ratio: 5
  abst_lambda: 0.1
  cost_lambda: 1e-5
base_model: meta-llama/Llama-3.2-1B-Instruct
large_model: meta-llama/Llama-3.1-8B-Instruct
batch_size: 100
max_input_length: 512
online:
  enable: true
  initial_xi_base: 0.05
  initial_xi_large: 0.05
  initial_phi_base: 0.5
  lr_tau: 0.05
  lr_M: 0.05
  error_penalty: 10
verification_fn: surrogate_token_probs
uncertainty_fn: surrogate_token_probs
uncertainty_samples: 1
precomputed:
  enable: true
  generation: true
  verification: true
  uncertainty: true
  path: /home/azureuser/caf83/helm/followup_results/run_20250506_231520_first_llama_medmcqa
dataset:
  name: openlifescienceai/medmcqa
  subset: null
  split: validation
  num_samples: 1000
device: cuda:0
name_postfix: debug
