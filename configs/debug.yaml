seed: 42
results_dir: results
max_new_tokens: 512 #Keep it small to start with
base_gen_cost: 1.0
large_inf_cost: 0.55
large_gen_cost: 10.0
expert_cost: 100.0
#base_model: HuggingFaceTB/SmolLM-1.7B-Instruct
base_model: meta-llama/Llama-3.2-1B-Instruct
large_model: meta-llama/Llama-3.2-3B-Instruct
#large_model: /mnt/pdata/caf83/helm/me-llama/physionet.org/files/me-llama/1.0.0/MeLLaMA-13B-chat
batch_size: 7
max_input_length: 512
online:
  enable: false
  initial_uncertainty_threshold_base: 300
  initial_uncertainty_threshold_large: 300
  initial_M: 1
  lr_tau: 0.1
  lr_M: 0.005
  error_penalty: 10
sft:
  enable: false
  learning_rate: 1e-4
  buffer_size: 1
  lora_r: 32
  lora_alpha: 64
  lora_dropout: 0.1
verification_fn: surrogate_token_probs
uncertainty_fn: verdict_distribution_entropy
precomputed:
  enable: true
  path: /home/azureuser/caf83/helm/results/20250117/run_20250117_013018_ai2arc_challenge_models_1_8/results_ai2arc_challenge_models_1_8.csv
dataset:
  name: allenai/ai2_arc
  subset: ARC-Challenge
  split: test
  num_samples: -1
device: cuda:0
name_postfix: arc2challenge_1_8


