seed: 42
results_dir: results
max_new_tokens: 3 #Keep it small to start with
base_gen_cost: 1.0
large_inf_cost: 1.0
large_gen_cost: 25.0
expert_cost: 100.0
#base_model: HuggingFaceTB/SmolLM-1.7B-Instruct
base_model: meta-llama/Llama-3.2-3B-Instruct
large_model: meta-llama/Llama-3.1-8B-Instruct
#large_model: /mnt/pdata/caf83/helm/me-llama/physionet.org/files/me-llama/1.0.0/MeLLaMA-13B-chat
probability_threshold: 1.0
uncertainty_threshold: 2.0
batch_size: 7
max_input_length: 512
num_samples: 1000
verification_fn: surrogate_token_probs
uncertainty_fn: per_token_entropy
prompt_template: 'Please answer with only one of the multiple choice option in the brackets.'
device: cuda:0
name_postfix: llama_3_8_b
